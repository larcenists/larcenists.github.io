<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="" />
    <meta name="description" content="" />
    <link href="default.css" rel="stylesheet" type="text/css" />
    <link href="benchmarks.css" rel="stylesheet" type="text/css" />
    <link rev="made" href="mailto:larceny@ccs.neu.edu" />
    <title>
      The Larceny Project -- R7RS Benchmarks
    </title>
    <style type="text/css">
      .red    { color: red; }
    </style>
  </head>

<body>

<!-- start header -->
<div id="strip1">&nbsp;</div>
<div id="strip2">&nbsp;</div>
<div id="header">
  <div id="logo">
    <h1><a href="#">
        <img src="images/larceny.png" alt="The Larceny Project"/>
        </a>
    </h1>
  </div>
</div>
<!-- end header -->

<!-- start page -->

<div id="page">
<!-- start content -->
<div id="content">


<div class="post">
<h1 class="title">Description of Benchmarks</h1>

<div class="entry">
<p>
The benchmarks described below are portable
<a href="http://www.scheme-reports.org/">R7RS</a>
programs.
None define any libraries.
Each description of a benchmark begins
with a link to its source code, omitting
<a href="R7src/common.scm">the part that is shared
by all of these benchmarks</a>.
</p>
<p>
All of these benchmarks, their inputs, and the Unix
script used to run them, are
<a href="https://github.com/larcenists/larceny/tree/master/test/Benchmarking/R7RS">online</a>
and can be downloaded using <code>git</code> or <code>svn</code>.
</p>

<p>
The timings report execution time only, as calculated using
<code>current-jiffy</code>.
</p>
</div>
</div>


<div class="post">
<h4 class="title"><a name="geometricMean">geometricMean</a></h4>

<div class="entry">
<p>
This pseudo-benchmark is an aggregate statistic that
shows the geometric mean for all benchmarks.
Where other benchmarks display timings in seconds,
the numerical scores for the geometric mean show the
(geometric) average ratio of the system's time to
the fastest system's time.
An average ratio of 1.0 is the lowest possible, and
can be achieved only by a system that is fastest on
every benchmark.
</p>
<!-- p>
To discourage implementors from pursuing speed at the
expense of compatibility, systems that yield incorrect
results or cannot run a benchmark are arbitrarily
considered to be ten times as slow on that benchmark
as the slowest system that yields correct results.
</p -->
<p>
The R7RS (small) standard does not require implementations
to provide all of the R7RS standard libraries, and some
implementations are unable to run some of the benchmarks
for other reasons as well; furthermore, our benchmarking
script gives up on any benchmark that takes more than an
hour to run.
The geometric means for each system were calculated using
only the benchmarks that returned correct results in less
than an hour.
When implementations of the R7RS are more mature, the
geometric means will be recalculated to impose a penalty
for each benchmark an implementation is unable to run.
</p>
</div>
</div>


<div class="post">
<h3 class="title">Gabriel Benchmarks</h3>


<dl class="benchmarks">
<dt><a name="browse"></a><a href="R7src/browse.scm">browse</a></dt>
<dd>
Browsing a data base, a Gabriel benchmark, 2000 iterations.
[May be a test of <code>string->symbol</code> and/or
<code>symbol-&gt;string</code>.]
</dd>

<dt><a name="deriv"></a><a href="R7src/deriv.scm">deriv</a></dt>
<dd>
Symbolic differentiation, a Gabriel benchmark,
ten million iterations.
</dd>

<dt><a name="destruc"></a><a href="R7src/destruc.scm">destruc</a></dt>
<dd>
Destructive list operations, a Gabriel benchmark, 4000 iterations
of a 600x50 problem.
</dd>

<dt><a name="diviter"></a><a href="R7src/diviter.scm">diviter</a></dt>
<dd>
Divides 1000 by 2 using lists as a unary notation for integers,
a Gabriel benchmark, one million iterations.
This benchmark tests
<code>null?</code>, <code>cons</code>, <code>car</code>,
<code>cdr</code>, and little else.
</dd>

<dt><a name="divrec"></a><a href="R7src/divrec.scm">divrec</a></dt>
<dd>
This benchmark is the same as <code>diviter</code>
except it uses deep recursion instead of iteration.
</dd>

<dt><a name="puzzle"></a><a href="R7src/puzzle.scm">puzzle</a></dt>
<dd>
Combinatorial search of a state space, a Gabriel benchmark, 1000 iterations.
A test of arrays and classical compiler optimizations.
This benchmark was originally written in Pascal by Forrest Baskett.
</dd>

<dt><a name="triangl"></a><a href="R7src/triangl.scm">triangl</a></dt>
<dd>
Another combinatorial search similar to
<code><a href="#puzzle">puzzle</a></code>,
a Gabriel benchmark,
50 iterations.
</dd>

<dt><a name="tak"></a><a href="R7src/tak.scm">tak</a></dt>
<dd>
A triply recursive integer function related to the Takeuchi function,
a Gabriel benchmark.
1 iteration of <code>(tak 40 20 11)</code>.
A test of non-tail calls and arithmetic.
[Historical note:
The Symbolics 3600 performed 1 iteration of <code>(tak 18 12 6)</code>
in 0.43 seconds using generic arithmetic.
On our test machine, Larceny runs that benchmark in 0.00016 seconds.
That's 2500 times as fast.]
</dd>

<dt><a name="takl"></a><a href="R7src/takl.scm">takl</a></dt>
<dd>
Calculates <code>(tak 40 20 12)</code>, which is faster than
calculating <code>(tak 40 20 11)</code>, using the same recursive
algorithm as for the <code><a href="#tak">tak:32:16:8</a></code>
benchmark but using lists to represent integers.  This too was a
Gabriel benchmark (with different arguments).  1 iteration.
</dd>

<dt><a name="ntakl"></a><a href="R7src/ntakl.scm">ntakl</a></dt>
<dd>
The <code><a href="#takl">takl</a></code> benchmark contains a
peculiar boolean expression.  Rewriting that expression into a
more readable idiom allows some compilers to generate better
code for it.
</dd>

<dt><a name="cpstak"></a><a href="R7src/cpstak.scm">cpstak</a></dt>
<dd>
The <code><a href="#tak">tak:40:20:11</a></code> benchmark
in continuation-passing style, 1 iteration.
A test of closure creation.
</dd>

<dt><a name="ctak"></a><a href="R7src/ctak.scm">ctak</a></dt>
<dd>
The <code><a href="#tak">tak:32:16:8</a></code> benchmark
in continuation-capturing style, 1 iteration.
A test of <code>call-with-current-continuation</code>.
</dd>

</dl>
</div>



<div class="post">
<h3 class="title">Numerical Benchmarks</h3>

<dl class="benchmarks">

<dt><a name="fib"></a><a href="R7src/fib.scm">fib</a></dt>
<dd>
Doubly recursive computation of the 40th fibonacci number
(102334155), using <code>(&lt; n 2)</code> to terminate the
recursion; 5 iterations.
</dd>

<dt><a name="fibc"></a><a href="R7src/fibc.scm">fibc</a></dt>
<dd>
A version of <code>fib</code> that uses first class continuations;
written by Kent Dybvig.  Calculates the 30th Fibonacci number
(832040) 10 times.
</dd>

<dt><a name="fibfp"></a><a href="R7src/fibfp.scm">fibfp</a></dt>
<dd>
Calculation of the 35th Fibonacci number using inexact numbers;
10 iterations.
A test of floating point arithmetic.
Uses essentially the same code as the <code><a href="#fib">fib</a></code>
benchmark.
</dd>

<dt><a name="sum"></a><a href="R7src/sum.scm">sum</a></dt>
<dd>
Sums the integers from 0 to 10000, 200000 iterations.
</dd>

<dt><a name="sumfp"></a><a href="R7src/sumfp.scm">sumfp</a></dt>
<dd>
Sums the integers from 0 to 1e6, 500 iterations.
A test of floating point arithmetic.
Uses essentially the same code as the <code><a href="#sum">sum</a></code>
benchmark.
</dd>

<dt><a name="fft"></a><a href="R7src/fft.scm">fft</a></dt>
<dd>
Fast Fourier Transform on 65536 real-valued points, 100 iterations.
A test of floating point arithmetic.
</dd>

<dt><a name="mbrot"></a><a href="R7src/mbrot.scm">mbrot</a></dt>
<dd>
Generation of a Mandelbrot set, 1000 iterations on a problem of
size 75.
A test of floating point arithmetic on reals.
</dd>

<dt><a name="mbrotZ"></a><a href="R7src/mbrotZ.scm">mbrotZ</a></dt>
<dd>
Same as the <code><a href="#mbrot">mbrot</a></code> benchmark,
but using complex instead of real arithmetic.
</dd>

<dt><a name="nucleic"></a><a href="R7src/nucleic.scm">nucleic</a></dt>
<dd>
Determination of a nucleic acid's spatial structure, 50 iterations.
A test of floating point arithmetic, and a real program.
</dd>

<dt><a name="pi"></a><a href="R7src/pi.scm">pi</a></dt>
<dd>
A bignum-intensive benchmark that calculates digits of pi.
</dd>

<dt><a name="pnpoly"></a><a href="R7src/pnpoly.scm">pnpoly</a></dt>
<dd>
Testing to see whether a point is contained within a 2-dimensional
polygon, 1000000 iterations (with 12 tests per iteration).
A test of floating point arithmetic.
</dd>

<dt><a name="ray"></a><a href="R7src/ray.scm">ray</a></dt>
<dd>
Ray tracing a simple scene, 50 iterations.
A test of floating point arithmetic.
This program is translated from the Common Lisp code in
Example 9.8 of Paul Graham's book on ANSI Common Lisp.
</dd>

<dt><a name="simplex"></a><a href="R7src/simplex.scm">simplex</a></dt>
<dd>
Simplex algorithm, one million iterations.
A test of floating point arithmetic, and a real program.
</dd>

</dl>
</div>



<div class="post">
<h3 class="title">Kernighan and Van Wyk Benchmarks</h3>

<div class="entry">
<p>
Brian W Kernighan and Christopher J Van Wyk wrote a set of small
<a href="http://cm.bell-labs.com/cm/cs/who/bwk/interps/pap.html">benchmarks</a>
to compare the performance of several scripting languages, including
C and Scheme.  Marc Feeley and I modified some of these benchmarks
to correct bugs and to increase the number of iterations.
When I translated them into R6RS Scheme, I rewrote most of
them into slightly more idiomatic Scheme.
</p>
</div>


<dl class="benchmarks">

<dt><a name="ack"></a><a href="R7src/ack.scm">ack</a></dt>
<dd>
A version of the Ackermann function, with arguments 3,12.
Two iterations.
</dd>

<dt><a name="array1"></a><a href="R7src/array1.scm">array1</a></dt>
<dd>
This benchmark allocates, initializes, and copies some fairly
large one-dimensional arrays.  500 iterations on a problem
size of one million.
</dd>

<dt><a name="string"></a><a href="R7src/string.scm">string</a></dt>
<dd>
This tests <code>string-append</code> and <code>substring</code>,
and very little else.  25 iterations on a problem size of 500000.
</dd>

<dt><a name="sum1"></a><a href="R7src/sum1.scm">sum1</a></dt>
<dd>
This benchmark reads and sums 100,000 floating point numbers
25 times.  It is primarily a test of floating point input.
</dd>

<dt><a name="cat"></a><a href="R7src/cat.scm">cat</a></dt>
<dd>
This file-copying benchmark is a simple test of character i/o.
It copies the King James Bible 50 times.
</dd>

<dt><a name="tail"></a><a href="R7src/tail.scm">tail</a></dt>
<dd>
This benchmark performs considerable character i/o.
It prints the King James Bible verse by verse, in reverse
order of the verses, 25 times.
</dd>

<dt><a name="wc"></a><a href="R7src/wc.scm">wc</a></dt>
<dd>
Another character i/o benchmark.
It counts the number of words in the King James Bible
50 times.
</dd>

</dl>
</div>


<div class="post">
<h3 class="title">More Input/Output Benchmarks</h3>

<dl class="benchmarks">

<dt><a name="read1"></a><a href="R7src/read1.scm">read1</a></dt>
<dd>
Reads <code>nboyer.scm</code> 2500 times.
</dd>

</dl>
</div>


<div class="post">
<h3 class="title">Other Benchmarks</h3>

<dl class="benchmarks">

<dt><a name="compiler"></a><a href="R7src/compiler.scm">compiler</a></dt>
<dd>
A compiler kernel that looks as though it was written by Marc Feeley.
2000 iterations on a 47-line input.
</dd>

<dt><a name="conform"></a><a href="R7src/conform.scm">conform</a></dt>
<dd>
A type checker written by Jim Miller, 500 iterations.
</dd>

<dt><a name="dynamic"></a><a href="R7src/dynamic.scm">dynamic</a></dt>
<dd>
Dynamic type inference, self-applied, 500 iterations.
Written by Fritz Henglein.
A real program.
</dd>

<dt><a name="earley"></a><a href="R7src/earley.scm">earley</a></dt>
<dd>
Earley's parsing algorithm, parsing a 15-symbol input according to one
of the simplest ambiguous grammars, 1 iteration.
A real program, applied to toy data whose exponential behavior
leads to a peak heap size of half a gigabyte or more.
</dd>

<dt><a name="graphs"></a><a href="R7src/graphs.scm">graphs</a></dt>
<dd>
This program was provided by Andrew Wright, but we don't know much
about it, and would appreciate more information.
This higher order program creates closures almost as often as it
performs non-tail procedure calls.
Three iterations on a problem of size 7.
</dd>

<dt><a name="lattice"></a><a href="R7src/lattice.scm">lattice</a></dt>
<dd>
Another program that was provided by Andrew Wright,
though it may have been written by Jim Miller.
It enumerates the order-preserving maps between finite lattices.
10 iterations.
</dd>

<dt><a name="matrix"></a><a href="R7src/matrix.scm">matrix</a></dt>
<dd>
Another program that was provided by Andrew Wright.
Computes maximal matrices; similar to some puzzle programs.
2500 iterations on a problem of size 5.
</dd>

<dt><a name="maze"></a><a href="R7src/maze.scm">maze</a></dt>
<dd>
Constructs a maze on a hexagonal grid, 10000 iterations.
Written by Olin Shivers.
</dd>

<dt><a name="mazefun"></a><a href="R7src/mazefun.scm">mazefun</a></dt>
<dd>
Constructs a maze on a rectangular grid using purely functional style,
10000 iterations on a problem of size 11.
Written by Marc Feeley.
</dd>

<dt><a name="nqueens"></a><a href="R7src/nqueens.scm">nqueens</a></dt>
<dd>
Computes the number of solutions to the 13-queens problem,
10 times.
</dd>

<dt><a name="paraffins"></a><a href="R7src/paraffins.scm">paraffins</a></dt>
<dd>
Computes the number of paraffins that have 23 carbon atoms,
10 times.
</dd>

<dt><a name="parsing"></a><a href="R7src/parsing.scm">parsing</a></dt>
<dd>
Parses the <code>nboyer</code> benchmark 2500 times
using a scanner and parser generated using Will Clinger's
LexGen and ParseGen.
</dd>

<dt><a name="peval"></a><a href="R7src/peval.scm">peval</a></dt>
<dd>
Partial evaluation of Scheme code, 2000 iterations.
Written by Marc Feeley.
</dd>

<dt><a name="primes"></a><a href="R7src/primes.scm">primes</a></dt>
<dd>
Computes the primes less than 1000, 10000 times, using
a list-based Sieve of Eratosthenes.
Written by Eric Mohr.
</dd>

<dt><a name="quicksort"></a><a href="R7src/quicksort.scm">quicksort</a></dt>
<dd>
This is a quicksort benchmark.
(That isn't as obvious as it sounds.  The <code>quicksort</code>
benchmark distributed with Gambit is a bignum benchmark,
not a quicksort benchmark.  See the comments in
<a href="R7src/quicksort.scm">the code</a>.)
Sorts a vector of 10000 random integers 2500 times.
Written by Lars Hansen, and restored to its original glory
by Will Clinger.
</dd>

<dt><a name="scheme"></a><a href="R7src/scheme.scm">scheme</a></dt>
<dd>
A Scheme interpreter evaluating a merge sort of 30 strings,
100000 iterations.
Written by Marc Feeley.
</dd>

<dt><a name="slatex"></a><a href="R7src/slatex.scm">slatex</a></dt>
<dd>
Scheme to LaTeX processor, 500 iterations.
A test of file i/o and probably much else.
Part of a real program written by Dorai Sitaram.
</dd>

</dl>
</div>


<div class="post">
<h3 class="title">Garbage Collection Benchmarks</h3>

<dl class="benchmarks">

<dt><a name="nboyer"></a><a href="R7src/nboyer.scm">nboyer</a></dt>
<dd>
An updated and exponentially scalable version of the
<code><a href="#boyer">boyer</a></code> benchmark.
The <code>nboyer</code> benchmark's data structures are
considerably more appropriate than the data structures used in the
original <code><a href="#boyer">boyer</a></code> benchmarks.
These timings are for 1 iteration on
a problem of size 5.
A test of lists, vectors, and garbage collection.
</dd>

<dt><a name="sboyer"></a><a href="R7src/sboyer.scm">sboyer</a></dt>
<dd>
A version of <a href="#nboyer">nboyer</a> that has been tuned (by Henry
Baker) to reduce storage allocation, making it less of a garbage collection
benchmark and more of a compiler benchmark.  Only 4 lines of code were
changed, and another 7 lines of code were added.
These timings are for 1 iteration on a problem of size 5.
</dd>

<dt><a name="gcbench"></a><a href="R7src/gcbench.scm">gcbench</a></dt>
<dd>
This program was written to mimic the phase structure that has been
conjectured for a class of application programs for which garbage
collection may represent a significant fraction of the execution time.
This benchmark warms up by allocating and then dropping a large
binary tree.
Then it allocates a large permanent tree and a permanent array
of floating point numbers.
Then it allocates considerable tree storage in seven phases,
increasing the tree size in each phase but keeping the total
storage allocation approximately the same for each phase.
Each phase is divided into two subphases.  The first subphase allocates
trees top-down using side effects, while the second subphase allocates
trees bottom-up without using side effects.
This benchmark was written in Java by John Ellis and Pete Kovac,
modified by Hans Boehm, and translated into Scheme, Standard ML,
C++, and C by William Clinger;
it has had too much influence on implementors of production
garbage collectors.
The timings shown are for 1 iteration on problem size 20.
</dd>

<dt><a name="mperm"></a><a href="R7src/mperm.scm">mperm</a></dt>
<dd>
The <code>mperm20:10:2:1</code> benchmark
is a severe test of storage allocation and garbage collection.
At the end of each of the 20 iterations, the oldest half of the
live storage becomes garbage.
This benchmark is particularly difficult for generational garbage
collectors, since it violates their assumption that young objects
have a shorter future life expectancy than older objects.
<strong>
The <code>perm9</code> benchmark distributed with Gambit
does not have that property.
</strong>
</dd>

</dl>
</div>


<div class="post">
<h3 class="title">Synthetic Benchmarks for R7RS</h3>

<div class="entry">
<p>
The R6RS and R7RS added several new features that had not been tested by
older benchmarks because they were not a standard part of
Scheme.  Most of the following synthetic benchmarks were
derived from Larceny's test suites for these features.
</p>
</div>

<dl class="benchmarks">

<dt><a name="equal"></a><a href="R7src/equal.scm">equal</a></dt>
<dd>
This benchmark tests the R7RS <code>equal?</code> predicate
on some fairly large structures of various shapes, including
circular structures.
</dd>

<dt><a name="bv2string"></a><a href="R7src/bv2string.scm">bv2string</a></dt>
<dd>
This benchmark tests conversions between bytevectors
and Unicode.
</dd>

</dl>
</div>



</div>

<!-- end content -->

<!-- start sidebar -->

<div id="sidebar">
<ul>
<li>
    <h2><b>Download</b> Larceny</h2>
    <ul>
    <li><a href="download.html"><strong>Larceny</strong>
        </a></li>
    <li><a href="download-petit.html"><strong>Petit
        Larceny</strong></a></li>
    <li><a href="CommonLarceny/download.html"><strong>Common
        Larceny</strong>
        </a></li>
    <li><a href="licensing.html">Licensing</a></li>
    </ul>
</li>
<li>
    <h2><b>About</b> Larceny</h2>
    <ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="overview.html">Overview</a></li>
    <li><a href="doc.html">Documentation</a></li>
    <li><a href="research.html">Research</a></li>
    <li><a href="dev.html">Development</a></li>
    <li><a href="history.html">History</a></li>
    <li><a href="benchmarks.html">Benchmarks</a></li>
    </ul>
</li>
</ul>
</div>

<!-- end sidebar -->

<div style="clear: both;">&nbsp;</div>

<!-- end page -->

<!-- hr />

  <p>
    <a href="http://validator.w3.org/check/referer"><img
        style="border:0;width:88px;height:31px"
        src="http://www.w3.org/Icons/valid-xhtml10"
        alt="Valid XHTML 1.0!" height="31" width="88" /></a>
  </p>

<div>
<a href="mailto:larceny@ccs.neu.edu">larceny@ccs.neu.edu</a><br />
</div>

<p>
Last updated 7 March 2015.
</p -->

</div>

<!-- start footer -->

<div id="footer">
<p id="legal">&copy; 2008 William D Clinger.
    Design by <a href="http://www.nodethirtythree.com/">NodeThirtyThree</a>
    and <a href="http://www.freecsstemplates.org/">Free CSS Templates</a>.
</p>
</div>

<!-- end footer -->

</body>
</html>
